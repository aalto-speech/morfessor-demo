#!/usr/bin/env pypy

from __future__ import print_function
from ConfigParser import SafeConfigParser
import os
import sys
import string
import random

os.chdir(os.path.dirname(__file__))
sys.path.append(os.path.dirname(__file__))

from bottle import Bottle, run, static_file

import morfessor
import flatcat

import logging

logging.basicConfig(level=logging.INFO)

application = demo = Bottle()

possible_static_dirs = [[os.path.dirname(os.path.realpath(__file__)), 'static'],
                           #['/', 'usr', 'share', 'morfessor-demo', 'static'],
                           [os.path.dirname(os.path.realpath(__file__)), '..', 'share', 'morfessor-demo', 'static']]

real_static_dir = './static'
for psd in possible_static_dirs:
    if os.path.exists(os.path.join(*psd)):
        real_static_dir = os.path.join(*psd)
print("Using {} as static dir".format(real_static_dir))

def load_models():
    possible_model_dirs = [[os.path.dirname(os.path.realpath(__file__)), 'models'],
                           #['/', 'usr', 'share', 'morfessor-demo-data', 'models'],
                           #['/', 'work', 'asr', 'demos', 'morfessor-demo', 'models']]
                           ]

    model_dir = None
    for pmd in possible_model_dirs:
        if os.path.exists(os.path.join(os.path.join(*pmd), 'config')):
            model_dir = os.path.join(*pmd)
            break

    if model_dir is None:
        sys.exit("Model dir not found")
    else:
        print("Using {} as model dir".format(model_dir))

    io = morfessor.MorfessorIO(encoding='utf-8')
    fcio = flatcat.FlatcatIO(encoding='utf-8')
    scp = SafeConfigParser()
    scp.read(os.path.join(model_dir, 'config'))

    metadata = []
    models = {}
    mainmodels = []
    wordlists = {}
    notices = {}
    spec_chars = {}

    for section in scp.sections():
        key = section
        lang = scp.get(key, 'lang')
        desc = scp.get(key, 'desc')

        metadata.append((lang, key, desc))

        mainmodel = None
        if scp.has_option(key, 'model'):
            models[key] = io.read_binary_model_file(os.path.join(model_dir, scp.get(key, 'model')))
            mainmodel = key

        if scp.has_option(key, 'annomodel'):
            annokey = "{}anno".format(key)
            models[annokey] = io.read_binary_model_file(os.path.join(model_dir, scp.get(key, 'annomodel')))
            if mainmodel is None:
                mainmodel = annokey

        if scp.has_option(key, 'flatcatmodel'):
            flatcatkey = "{}flatcat".format(key)
            models[flatcatkey] = fcio.read_binary_model_file(
                os.path.join(model_dir, scp.get(key, 'flatcatmodel')))
            if mainmodel is None:
                mainmodel = flatcatkey

        if mainmodel is not None:
            mainmodels.append((key, mainmodel))

        if scp.has_option(key, 'evalset'):
            wordlists["{}eval".format(key)] = io.read_annotations_file(os.path.join(model_dir, scp.get(key, 'evalset')))

        if scp.has_option(key, 'trainlist'):
            wordlists["{}train".format(key)] = list(io.read_corpus_list_file(os.path.join(model_dir, scp.get(key, 'trainlist'))))

        if scp.has_option(key, 'non_latin_chars'):
            spec_chars[key] = scp.get(key, 'non_latin_chars').split()
        if scp.has_option(key, 'notice'):
            notices[key] = scp.get(key, 'notice')

    return metadata, mainmodels, models, wordlists, notices, spec_chars


def find_special_chars(model):
    try:
        lexitems = model._all_chars.items()
    except AttributeError:
        lexitems = model._lexicon_coding.atoms.items()
    all_chars = set(k for k,v in lexitems if v > 10)
    return list(all_chars - set(string.ascii_lowercase) - set(string.punctuation) - set(string.digits))

metadata, mainmodels, models, wordlists, notices, spec_chars = load_models()


@demo.route('/')
def htmlpage():
    return static_file('index.html', root=real_static_dir)


@demo.route('/static/<filename>')
def staticfiles(filename):
    return static_file(filename, root=os.path.join(real_static_dir, 'static'))


@demo.route('/models')
def get_models():
    return dict(models=metadata)


def format_nbest(nbest, correct):
    costs = [n[1] for n in nbest]
    mc = max(costs)
    rels = [mc/c for c in costs]
    fonts = [r / sum(rels) for r in rels]

    return [{'segm': tuple(n[0]), 'cost': n[1], 'fsize': f, 'correct': tuple(n[0]) in correct}
            for n, f in zip(nbest, fonts)]

def format_onebest(best, correct):
    detagged = tuple(unicode(x) for x in flatcat.FlatcatModel.detag_word(best[0]))
    rendered = [unicode(x) for x in best[0]]
    return [{'segm': rendered, 'cost': best[1], 'fsize': 0.3,
            'correct': detagged in correct}]

@demo.route('/segment/<model>/<word>')
def segment_word(model, word):

    word = word.decode("utf-8")
    result = {}
    correct = set()
    evalset = "{}eval".format(model)
    if evalset in wordlists:
        if word in wordlists[evalset]:
            correct = set(tuple(x) for x in wordlists[evalset][word])
            result['correct'] = [[unicode(x) for x in w] for w in correct]

    if model in models:
        result['standard'] = format_nbest(models[model].viterbi_nbest(word, 5), correct)
    anno_model = "{}anno".format(model)
    if anno_model in models:
        result['anno'] = format_nbest(models[anno_model].viterbi_nbest(word, 5), correct)
    flatcat_model = "{}flatcat".format(model)
    if flatcat_model in models:
        result['flatcat'] = format_onebest(models[flatcat_model].viterbi_analyze(word), correct)

    return result


def model_info_pregen(key, modelname):
    anno_modelname = "{}anno".format(key)
    flatcat_modelname = "{}flatcat".format(key)
    eval_name = "{}eval".format(key)
    trai_name = "{}train".format(key)

    model = models[modelname]

    result = {}
    try:
        result['num_compounds'] = model._num_compounds
    except AttributeError:
        result['num_compounds'] = model._num_compounds if model._segment_only else len(model.get_compounds())
    result['corpus_weight'] = model._corpus_coding.weight
    try:
        result['num_morphs'] = model.num_constructions
    except AttributeError:
        result['num_morphs'] = len(model.get_constructions())

    if key in spec_chars:
        result['special_chars'] = spec_chars[key]
    else:
        result['special_chars'] = find_special_chars(model)

    result['supervised'] = False
    if anno_modelname in models:
        anno_model = models[anno_modelname]
        result['supervised'] = True
        result['num_annotations'] = len(anno_model.annotations)
        result['annotation_weight'] = anno_model._annot_coding.weight

    if eval_name in wordlists:
        result['evalwords'] = random.sample(wordlists[eval_name].keys(), 1000) if len(wordlists[eval_name]) > 1000 else list(wordlists[eval_name].keys())

    if trai_name in wordlists:
        result['trainwords'] = random.sample(list(w[1] for w in wordlists[trai_name]), 1000) if len(wordlists[trai_name]) > 1000 else list(w[1] for w in wordlists[trai_name])

    if key in notices:
        result['notice'] = notices[key]
    return result


info = {key: model_info_pregen(key, model) for (key, model) in mainmodels}


@demo.route("/info/<modelname>")
def model_info(modelname):
    return info[modelname]


if __name__ == "__main__":
    run(demo, host="0.0.0.0", port=8080)
